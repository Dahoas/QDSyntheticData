# [Beyond Human Data: Scaling Self-Training for Problem-Solving with Language Models](https://arxiv.org/abs/2312.06585)

## Summary

Applies expert iteration to LLM fine-tuning on reasoning tasks. Finds the technique scales favorably with model size and that RL improves pass@96 relative to continued SFT.

## Relevance to survey topic (1-5)

Relevance: 3

## Algorithms

- Rest^EM (expert iteration)

## Benchmarks

Tasks evaluated.

- MATH
- APPS

## Metric Results

- How is quality measured: final answer correctness
- How is diversity measured: N/A
- Fine-tuning results?

## Paper Tags

Tag paper with relevant categories. See [here](https://github.com/Dahoas/QDSyntheticData/blob/main/papers/categories.json) for list of all category tags.

1. SYNTH
2. REASONING
