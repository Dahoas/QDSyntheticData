# [Prompt Programming for Large Language Models: Beyond the Few-Shot Paradigm](https://arxiv.org/abs/2102.07350)

## Summary

This paper argues that few-shot in-context examples are primarily used by a LLM to locate the task to solve, rather than to actually learn to solve it.
In French-to-English translation, it is shown that appropriate 0-shot prompts can actually outperform few-shot prompts.
Additionally, the paper systematically analyzes the process of engineering a prompt for a given task, including the idea of "metaprompts" (a prompt that is used to generate task-specific prompts).

## Relevance to survey topic (1-5)

Relevance: 2

## Algorithms

The only algorithm presented is metaprompt programming: write a prompt that is used to generate task-specific prompts. This is, however, not evaluated.

## Benchmarks

- WMT'14 Fr-En translation (used to compare few-shot in-context learning with GPT-3 against zero-shot with prompt engineering).

## Metric Results

- How is quality measured? SacreBLEU

## Other comments

This paper works with non-instruction-tuned LLMs.
Its relevance to synthetic data generation is restricted to the short section on metaprompt programming.