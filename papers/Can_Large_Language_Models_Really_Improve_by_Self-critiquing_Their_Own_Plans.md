# [Can Large Language Models Really Improve by Self-critiquing Their Own Plans?](https://arxiv.org/abs/2310.08118)


ID: Number of paper in list of papers (ordered by date of accepted pr)

## Summary

Evaluates the effectiveness of iterative-feedback in LM's for planning tasks. hey restrict themselves to GPT-4, finding that self-critiquing diminishes performance due to high false positive rates (compared to a heuristic based verifier).

They additionally evaluate how much feedback levels influence plan generation performance: marginal improvements from more extensive feedback vs binary feedback.

## Relevance to survey topic (1-5)

Relevance: 2

## Algorithms

- Iterative Feedback

## Benchmarks

Tasks evaluated.

- Blocksworld 


## Metric Results

- How is quality measured?
    binary: plan is correct or not

## Paper Tags

Tag paper with relevant categories. See [here](https://github.com/Dahoas/QDSyntheticData/blob/main/papers/categories.json) for list of all category tags.

1. FEEDBACK

## Relevant related work

Add them to the spreadsheet. No need to link them in the report.

## Other comments

Anything else you found interesting/noteworthy.

## Questions

Questions you had about the paper
