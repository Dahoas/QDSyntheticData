# [ACES: GENERATING DIVERSE PROGRAMMING PUZZLES WITH AUTOTELIC LANGUAGE MODELS AND SEMANTIC DESCRIPTORS](https://arxiv.org/abs/2310.10692)

## Summary

Fine-tunes 1.3B model on python programming puzzles and generates synthethic (Q,A) pairs. Pairs are quantized with behavioral descriptors (phenotypes) MAP-Elites style. New samples are then generated by first picking a target cell, sampling, characterized by ChatGPT, and inserting into the archive if compiles successfully. Overall fine-tuning performance is poor when compared to a rejection sampled baseline.

## Algorithms

- ACES (MapElites + randomly selected target cell)
- ELM
- Rejection sampling

## Benchmarks

- Python programming puzzles (P3)

## Metric Results

- Quality: checking whether proposed (Q, A) pair successfully compiles
- Diversity:
    - Number of cells discovered
    - Number of cells discovered beyond training data
    - Number of valid puzzles
    - Entropy of puzzle cell distribution
    - Embedded average pairwise cosine distance

Diversity seems to correlate poorly with test performance.


## Questions

- Perhaps poor performance is due to lack of good quality criteria?