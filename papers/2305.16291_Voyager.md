# [Voyager: An Open-Ended Embodied Agent with Large Language Models](https://arxiv.org/abs/2305.16291)

ID: 116

## Summary

Voyager is a lifelong learning agent, for the open-ended world of Minecraft. 
It continuously explores, acquires diverse skills, and makes novel discoveries without human intervention. 
It consists of 3 components: 
1. A curriculum is automatically generated from an LLM (suggests new subgoals to pursue at a particular environment state). 
2. An iterative prompting mechanism that is taken where the goal is to write a piece of executable code representing this subgoal. This means no human intervention is required. 
3. A skill library stores previously-generated pieces of code for later use. 

## Relevance to survey topic (1-5)

Relevance: 4

## Algorithms

It is a lifelong learning agent with algorithm consisting of three key components: 
1) an automatic curriculum that maximizes exploration,
2) an ever-growing skill library of executable code
for storing and retrieving complex behaviors, and
3) an iterative prompting mechanism that incorporates environment feedback,
4) execution errors, and self-verification for program improvement.

## Benchmarks

Compared with a few of the most representative algorithms as baselines (designed only for NLP tasks without embodiment). 

They evaluated Voyager and baselines on their exploration performance, tech tree mastery,
map coverage, and zero-shot generalization capability to novel tasks in a new world. 
With its self-driven exploration, Voyager significantly outperforms baselines at discovering new Minecraft items and skills continually (baselines fail to progress at various points). 
It obtains 3.3× more unique items, travels 2.3× longer distances, 
and unlocks key tech tree milestones up to 15.3× faster than prior SOTA.

- ReAct (Yao et al., 2022) uses chain-of-thought prompting by generating both reasoning
traces and action plans with LLMs. They provide it with our environment feedback and the agent states as
observations.
- Reflexion (Shinn et al., 2023) is built on top of ReAct with self-reflection to infer more
intuitive future actions. They provide it with execution errors and our self-verification module.
- AutoGPT (Richards, 2023) decomposes a high-level goal into multiple subgoals and executing them in a ReAct-style loop

- They do not directly compare with prior methods that take Minecraft screen pixels as input and
output low-level controls as focus is on pushing the limits of GPT-4 for lifelong embodied agent learning. 

## Metric Results

- How is quality measured? NA
- How is diversity measured? NA
- Fine-tuning results? NA

## Paper Tags

Paper falls under the following tags (to some extent): 

1. SEARCH? As it searches within the Minecraft environment
2. JUDGE? LLM verifier?
3. EVO? It's an open ended search space

## Other comments

Voyager interacts with GPT-4 via blackbox queries (no need for model parameter fine-tuning). 
The progressively more difficult curriculum is generated by GPT-4 based on the overarching goal of “discovering as many diverse things as possible”.
This approach can be perceived as an in-context form of novelty search. 
LLMs struggle to produce the correct action code consistently in one shot, hence the iterative prompting step. 
Instead of manually coding success checkers for each new task proposed by the automatic curriculum, they instantiate another GPT-4 agent for self-verification. 
This is more comprehensive than self-reflection. 

3 agents: curriculum agent (for proposing the next task), action agent (for code generation), and critic agent (for self-verification). 

Comparisons are made with existing LLM approaches that focus on self-reflection / inference-time refinement. 

