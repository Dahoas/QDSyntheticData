# [Quality-Diversity Generative Sampling for Learning with Synthetic Data](https://arxiv.org/abs/2312.14369)

ID: 257

## Summary

This paper deals with the problem that generative models can create synthetic training datasets, but may transfer biases to downstream tasks. 
It focuses on protecting quality and diversity when generating synthetic training datasets.
They propose quality-diversity generative sampling (QDGS), a framework for using quality-diversity optimisation using prompt guidance, without fine-tuning the generative model. 
It uses prompt guidance to sample balanced data from biased generative models, across a user-defined measure space. 
QDGS increases spread over desired attributes, described by user-defined language prompts, by exploring high dimensionality latent spaces.

Basically uses a latent space exploration algorithm to iteratively identify inputs for a generative model that produces an image. 
They iteratively update latent parameter by adding gradient of objective + gradient of measure functions. 

## Relevance to survey topic (1-5)

Relevance: 5

## Algorithms

- CMA-MAEGA (Covariance matrix adaptation map-annealing)

## Benchmarks

Tasks evaluated:

- Synthetic dataset of shapes and colours as proof of concept - repaired biases in shape classifiers.
- Generating synthetic images of faces with a diverse range of skin colours and ages - more uniform spread of synthetic facial image training data resulting in improved accuracy on dark-skinned faces.

## Metric Results

- How is quality measured? No measure, they use a negative prompt in the objective function f to guide towards high quality generations. 
- How is diversity measured? User-defined measure dimensions are specified as prompts. 
They estimate measured diversity (i.e., dimensions of diversity that are aligned with semantic concepts) in the resulting images by computing CLIP similarity scores to these language prompts. 

## Paper Tags

1. SYNTH

## Other comments

### QD algorithm 

CMA-MAEGA is a QD optimisation algorithm combining the following 2 QD algorithms:

CMA-MA - Covariance matrix adaptation map-annealing [1].
It's a update to MAP Elites.
MEGA - MAP-Elites via a Gradient Arborescence [2].
MEGA is a DQD (both the objective and measure functions are first-order differentiable) algorithm introduced in this paper.

### Searching over latent solutions: 

Searching over latent solutions is referred to as "latent space illumination" [3].
It's the problem of finding an input θ to a generative model, that produces diverse images across (a user defined) measure space.

Section 3.3 has a formalism of the algorithm. Figure 2 gives a high level overview. 

Summary:
Have objective function f for image generation.
We have k user defined measures (m_j), for each of these measures,
We wish to find an input θ that maximises f and gives diverse measures.
We map solutions for initial θ into the measure space.
θ is updated to θ' with objective-measure gradients (See equation 1 and algorithm 1).

The objective function f in their examples computes CLIP similarity scores of generated images with positive and negative language prompts (Equation 2).
Each measure function m_j also computes CLIP scores to determine the measures of diversity in the resulting images.

In synthetic face example, the objective function f is a weighted sum of three component
functions: a text objective, an image margin, and a regularization factor. Measure dimensions, are found with the following prompts:
x_m1= “A {feminine,masculine} person”,
x_m2= “A person with {light, dark} skin”,
x_m3 = “A person with {short, long} hair”, and
x_m4 = “A person in their {20, 50}s”.

## Relevant related work

[1] "Covariance matrix adaptation map-annealing" Fontaine and Nikolaidis, '23. https://arxiv.org/abs/2205.10752

[2] "Differentiable Quality Diversity" Fontaine and Nikolaidis, '21. https://arxiv.org/abs/2106.03894

[3] "Illuminating Mario Scenes in the Latent Space of a Generative Adversarial Network" Fontaine and Nikolaidis, '21. https://arxiv.org/abs/2106.03894

This paper is very related. It is a QD algorithm by the same authors that explores the continuous latent space of a GAN to extract levels that vary across a set of specified gameplay measures. 
