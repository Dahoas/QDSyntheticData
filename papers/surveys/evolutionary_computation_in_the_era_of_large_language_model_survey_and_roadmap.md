# [Evolutionary Computation in the Era of Large Language Model: Survey and Roadmap](https://arxiv.org/abs/2401.10034)

## Summary

The survey focuses on how LLMs enhance EAs and EAs enhance LLMs. In general, while EAs provide the search framework, LLMs provide the generative capability to serve as effective mutation operators. 

The paper also discusses future directions categorized into methods, theory, and application. Future methods discussed seem to center on improving LLM usability, interpretability, stability, and diversity. The authors also put forward that more must be done theoretically on convergence, algorithmic complexity, and sensitivity analysis. 

## Relevance to survey topic (1-5)

Relevance: 3

- mentions the QD problem directly in section II.A.2. Describes it as subproblem of "Multi-objective optimization"
- mentions using EA to improve prompts used for data augmentation III.A.3

## Algorithms (Mentioned)

- Quality-Diversity search [Evolving a diversity of virtual creatures through novelty search and local competition](https://dl.acm.org/doi/10.1145/2001576.2001606) [II.A.2]
- [Quality-Diversity through AI Feedback](https://arxiv.org/abs/2310.13032) [II.A.2]
- Evol-Instruct [WizardLM: Empowering Large Language Models to Follow Complex Instructions](https://arxiv.org/abs/2304.12244) [III.A.3]

## Other comments

For those interested, there are six tables in the paper that name the important cited papers in the survey. Maybe glance over if interested. 

