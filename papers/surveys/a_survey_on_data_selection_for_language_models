# [A Survey on Data Selection for Language Models](https://arxiv.org/pdf/2402.16827)

ID: Issue #162

## Summary

This survey presentes a detailed examination of data selection strategies emphasizing their critical role in the development and performance of language models across various training scenarios​. Mainly concentrates on those for pretraining LLMS and includes multitask training, instruction-tuning, alignment, in-context learning, and task-specific fine-tuning.


## Relevance to survey topic (1-5)

Relevance: 4

Very relevant as it includes a lot of methods for SFT data selection

## Algorithms (Mentioned)

- Evol-Instruct method for generating diverse data
- SemDeDup for deduplication but can be used for increasing diversity
- corest selection (geometry based) methods based on distances to k-means cluster center
- cynical data selection for domain specific selection
- Moore-Lewis selection for domain specific selection

## Benchmarks (Mentioned)

- Ultrafeedback
- Nectar
- DataComp and DataPerf (data centric benchmarks)


## Metrics and Methods Defined and Mentioned 

- utility function defined which is based on some metrics for selecting data 
- perplexity based for domain specific selection but can be used as a quality/complexity filtering
- Instruction-Following Difficulty metric for data selection 
- mutual information


## Relevant related work

[1] Amro Abbas, Kushal Tirumala, Dániel Simig, Surya Ganguli, and Ari S Morcos. Semdedup: Data-efficient learning at web-scale through semantic deduplication.  https://arxiv.org/pdf/2303.09540
[2] Amittai Axelrod. Cynical selection of language model training data. 2017. https://arxiv.org/pdf/1709.02279


## Other comments

The methods for data selection scoped in the paper are for model pretraining but most of them can be used for SFT data selection


