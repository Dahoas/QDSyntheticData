[Textbooks are all you need](https://arxiv.org/abs/2306.11644)


Following the success of TinyStories, this work we explore the improvement that can be obtained along a different axis: the quality of the data.

Data quality can dramatically change the shape of the scaling laws, potentially allowing to match the performance of large-scale models with much leaner training/models.


textbook-quality alignment: 
- it should be clear
- self-contained
- instructive
- balanced


phi-1-small: 
- 350M parameters
- tokenizer: codegen-mono
- 26B tokens
- 20 layers
- 16 heads of size 64
- 1024 hidden (16 x 64)


phi-1-base: 
    pretraining:
    - 1024 batch size
    - max learning rate: 1e-3 warmup on 750 steps weight decay: 0.1 for 36k steps (but then use the checkpoint at 24k steps)
    - epochs: 8
    finetuning:
    - batchsize: 256
    - learning rate: 1e-4 with 50 steps warmup, 0.01 weight decay
    - 6k steps 


phi-1:
- 1.3B parameters, trained for 4 days on 8 A100s
- 24 layers
- 2048 hidden
- 32 heads of size 64

- 6B "Textbook-quality" data from the web
- 1B synthetically generated texbooks and exercises dataset using GPT-3.5


## Dataset

CodeTextbook:
- A filtered code-language dataset, which is a subset of The Stack and StackOverflow, obtained by using a language model-based classifier (consisting of about 6B tokens).
- A synthetic textbook dataset consisting of <1B tokens of GPT-3.5 generated Python textbooks.

CodeExercises:
Each exercise is a docstring of a function that needs to be completed.
- A small synthetic exercises dataset consisting of âˆ¼180M tokens of Python exercises and solutions.

## Algorithm

1. Pick The Stack and stackoverflow raw dataset (35M documents)
2. Annotate 100k samples using GPT-4
3. Train a Random Forest Classifier that predicts the quality of a file/sample using the embedding from a pretrained CODEGEN model.

### Decontamination
- n-word analysis
- embedding / syntax-based distances L2 over codegen-mono | we calculate the (string) edit distance between the abstract syntax trees (ASTs) of two given code snippets.
    The AST distance successfully identifies overlapping sections between code pairs while being agnostic to non-syntax text such as variable/function naming, comments, and Python Docstrings

## Metrics

Diversity: the examples should cover a wide range of coding concepts, skills, and scenarios, and that they should vary in their level of difficulty, complexity, and style. Diversity is important for several reasons: it exposes the language model to different ways of expressing and solving problems in code, it reduces the risk of overfitting or memorizing specific patterns or solutions, and it increases the generalization and robustness of the model to unseen or novel tasks.

## Comments

Some details of the synthetic data generation is omitted for proprietary reasons.

Insights from the standard coding datasets:
- Many samples are not self-contained, meaning that they depend on other modules or files that are external to the snippet, making them hard to understand without additional context.
- Typical examples do not involve any meaningful computation, but rather consist of trivial or boilerplate code, such as defining constants, setting parameters, or configuring GUI elements
- Samples that do contain algorithmic logic are often buried inside complex or poorly documented functions, making them difficult to follow or learn from
- The examples are skewed towards certain topics or use cases, resulting in an unbalanced distribution of coding concepts and skills across the dataset.

Evidence of quality by just filtering:
- 12.9% on human eval after 96k (un-filtered) 
- 17.9% on human eval after 36k (filtered) 
- 20.12% on human eval using also synthetic data.

Simply prompting the model to produce a coding textbook or a set of exercises, even with some variation in the instructions or the parameters, will likely result in a very homogeneous and redundant dataset, where the same concepts and solutions are repeated over and over with minor changes.
One trick is inspired from tiny stories where it requires to use some word from a fixed vocabulary set. Another trick is to provide constraints on topics and target audience. eliciting diversity can also be achieved by constraining the function names.

Performance drops significantly with prompt length.


## Questions
- How was the data curated?